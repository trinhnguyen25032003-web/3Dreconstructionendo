{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "87b2a6c38b844a0897f9785b776892f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2dffeaf4e9e6403b936ec8e4a9b8b1f2",
              "IPY_MODEL_9bf6850a1f404c8fab2cc8d817f00265",
              "IPY_MODEL_62268b039da24070af54a96386b73537"
            ],
            "layout": "IPY_MODEL_2ba8e6c7df9243819eaf0b2e25d2f0b0",
            "tabbable": null,
            "tooltip": null
          }
        },
        "2dffeaf4e9e6403b936ec8e4a9b8b1f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_fe01f8b0f15a448ebc5f9b72a8243b0f",
            "placeholder": "​",
            "style": "IPY_MODEL_d4c57a39082a4c5c8bee1a29087cc9fa",
            "tabbable": null,
            "tooltip": null,
            "value": "config.json: "
          }
        },
        "9bf6850a1f404c8fab2cc8d817f00265": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_6c14828dba7f42319c2006ebcec0bb89",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d204b38752204c70957839264b9833cf",
            "tabbable": null,
            "tooltip": null,
            "value": 1
          }
        },
        "62268b039da24070af54a96386b73537": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_ae0d6123eb1244869f08ef165fb96a9a",
            "placeholder": "​",
            "style": "IPY_MODEL_90f495a2220147d8bd073753451d8605",
            "tabbable": null,
            "tooltip": null,
            "value": " 1.21k/? [00:00&lt;00:00, 101kB/s]"
          }
        },
        "2ba8e6c7df9243819eaf0b2e25d2f0b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe01f8b0f15a448ebc5f9b72a8243b0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4c57a39082a4c5c8bee1a29087cc9fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "6c14828dba7f42319c2006ebcec0bb89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "d204b38752204c70957839264b9833cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae0d6123eb1244869f08ef165fb96a9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90f495a2220147d8bd073753451d8605": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "89577ab8f36344869172995ad5d00ea9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbe3f9a732b944099f9fe14c14ed28ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a1d504a167f343faba22d24fce75fc5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0baec7fb4f1f434d8fca26114deed4bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "ff629129504e46e2b898ecbeed613f4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7770fd28ae0c416fa8136c1eeeeb7f30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "cec34eeaeb9c4d8ebab03341d571e6d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_a1d504a167f343faba22d24fce75fc5b",
            "placeholder": "​",
            "style": "IPY_MODEL_0baec7fb4f1f434d8fca26114deed4bb",
            "tabbable": null,
            "tooltip": null,
            "value": "model.safetensors: 100%"
          }
        },
        "301ca8a38f944eb5a0f257a369f95d08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_89577ab8f36344869172995ad5d00ea9",
            "max": 1643843860,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cbe3f9a732b944099f9fe14c14ed28ac",
            "tabbable": null,
            "tooltip": null,
            "value": 1643843860
          }
        },
        "6bc161a4ea964c5f807e47835d71e2be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_ff629129504e46e2b898ecbeed613f4b",
            "placeholder": "​",
            "style": "IPY_MODEL_7770fd28ae0c416fa8136c1eeeeb7f30",
            "tabbable": null,
            "tooltip": null,
            "value": " 1.64G/1.64G [00:08&lt;00:00, 163MB/s]"
          }
        },
        "c81bdf8037fc492290895e7411714ee8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff94c89011484bd6941eac47ebddcf3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cec34eeaeb9c4d8ebab03341d571e6d0",
              "IPY_MODEL_301ca8a38f944eb5a0f257a369f95d08",
              "IPY_MODEL_6bc161a4ea964c5f807e47835d71e2be"
            ],
            "layout": "IPY_MODEL_c81bdf8037fc492290895e7411714ee8",
            "tabbable": null,
            "tooltip": null
          }
        },
        "f754258eb36542a49bd2677d69771007": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1b8c3ef8c5546a8ace4bb7a938a2f6d",
              "IPY_MODEL_0004c453b65c4bbaa2668622a88122cd",
              "IPY_MODEL_48a5a05b71ee4e7c98059566f19192fe"
            ],
            "layout": "IPY_MODEL_87795ea95574475eaade7aedf9684bd6",
            "tabbable": null,
            "tooltip": null
          }
        },
        "f1b8c3ef8c5546a8ace4bb7a938a2f6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_d3716c8997fc4ed7bc8c2a67203130f6",
            "placeholder": "​",
            "style": "IPY_MODEL_aaa80626a0294d2ea0afaa5473e2f049",
            "tabbable": null,
            "tooltip": null,
            "value": "config.json: 100%"
          }
        },
        "0004c453b65c4bbaa2668622a88122cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_b97b3e247b644a398ba307b12998377f",
            "max": 845,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8697d47724734b93b97a84cf3cb797f2",
            "tabbable": null,
            "tooltip": null,
            "value": 845
          }
        },
        "48a5a05b71ee4e7c98059566f19192fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_e8131d99532d491b82b3cdd8ffb36d26",
            "placeholder": "​",
            "style": "IPY_MODEL_7f8e680449104c27b3789d0cf85be200",
            "tabbable": null,
            "tooltip": null,
            "value": " 845/845 [00:00&lt;00:00, 112kB/s]"
          }
        },
        "87795ea95574475eaade7aedf9684bd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3716c8997fc4ed7bc8c2a67203130f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aaa80626a0294d2ea0afaa5473e2f049": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "b97b3e247b644a398ba307b12998377f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8697d47724734b93b97a84cf3cb797f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8131d99532d491b82b3cdd8ffb36d26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f8e680449104c27b3789d0cf85be200": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "b4655b04f5fd42fa8b7a49a42859b601": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60f6da7b317148ecbefc52e8ff4e5198": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee53bb7a593243f5b27e0f33cbad1152": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b0148f609af402391604b6bbf273649": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "2408ec34b1534081b1fb1c26afb28ff6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5926d826b69e44258e5fe2dab4b8411c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "6ba0e5f3e06f4e0b8bde2c3fbfbcfc75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_ee53bb7a593243f5b27e0f33cbad1152",
            "placeholder": "​",
            "style": "IPY_MODEL_2b0148f609af402391604b6bbf273649",
            "tabbable": null,
            "tooltip": null,
            "value": "model.safetensors: 100%"
          }
        },
        "6fe65d9b03cd409490f057c5a9078da2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_b4655b04f5fd42fa8b7a49a42859b601",
            "max": 1336734448,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60f6da7b317148ecbefc52e8ff4e5198",
            "tabbable": null,
            "tooltip": null,
            "value": 1336734448
          }
        },
        "810ea732722c4099aea40caa96c2f564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_2408ec34b1534081b1fb1c26afb28ff6",
            "placeholder": "​",
            "style": "IPY_MODEL_5926d826b69e44258e5fe2dab4b8411c",
            "tabbable": null,
            "tooltip": null,
            "value": " 1.34G/1.34G [00:04&lt;00:00, 677MB/s]"
          }
        },
        "9af13f1bfbb94cd5b32a5a983740ac9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0775b43336544f6295381fa2ad158312": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ba0e5f3e06f4e0b8bde2c3fbfbcfc75",
              "IPY_MODEL_6fe65d9b03cd409490f057c5a9078da2",
              "IPY_MODEL_810ea732722c4099aea40caa96c2f564"
            ],
            "layout": "IPY_MODEL_9af13f1bfbb94cd5b32a5a983740ac9a",
            "tabbable": null,
            "tooltip": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "CELL 1"
      ],
      "metadata": {
        "id": "Kni8Bjxf2qX8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJr5XNgQlg3Z",
        "outputId": "15a574f1-3073-46c9-d875-0ca6b1a16147"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✅ Depth-Anything-3 đã tồn tại.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import sys\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "if not os.path.exists(\"Depth-Anything-3\"):\n",
        "    !git clone https://github.com/ByteDance-Seed/Depth-Anything-3\n",
        "    %cd Depth-Anything-3\n",
        "    !pip install -r requirements.txt\n",
        "    !pip install pycolmap triton\n",
        "    !pip install -e .\n",
        "    %cd /content\n",
        "else:\n",
        "    print(\"Depth-Anything-3 đã tồn tại\")\n",
        "\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 2"
      ],
      "metadata": {
        "id": "ExDDydsU2u7-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DA3-LARGE"
      ],
      "metadata": {
        "id": "9HQkJRLu4x5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import zipfile\n",
        "import gc\n",
        "from pathlib import Path\n",
        "from depth_anything_3.api import DepthAnything3\n",
        "\n",
        "ZIP_PATH = \"/content/drive/MyDrive/3D_reconstruction/datasets/FrameBuffer_RGB.zip\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/3D_reconstruction/simcol_output_blind_pose\"\n",
        "OUTPUT_DEPTH_DIR = os.path.join(OUTPUT_DIR, \"depth_pose_data\")\n",
        "\n",
        "MODEL_NAME = \"da3-large\"\n",
        "BATCH_SIZE = 18\n",
        "\n",
        "FX, FY = 227.60416, 237.5\n",
        "CX, CY = 227.60416, 237.5\n",
        "\n",
        "os.makedirs(OUTPUT_DEPTH_DIR, exist_ok=True)\n",
        "\n",
        "# Giải nén\n",
        "EXTRACT_PATH = \"/content/dataset_simcol_rgb\"\n",
        "if not os.path.exists(EXTRACT_PATH):\n",
        "    print(f\"Đang giải nén dataset...\")\n",
        "    with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
        "        zip_ref.extractall(EXTRACT_PATH)\n",
        "\n",
        "# List\n",
        "image_extensions = {'.png', '.jpg'}\n",
        "all_image_paths = sorted([\n",
        "    str(p) for p in Path(EXTRACT_PATH).rglob(\"*\")\n",
        "    if p.suffix.lower() in image_extensions\n",
        "])\n",
        "total_imgs = len(all_image_paths)\n",
        "print(f\"Tổng số ảnh: {total_imgs}\")\n",
        "\n",
        "# Intrinsic\n",
        "K = np.array([[FX, 0, CX], [0, FY, CY], [0, 0, 1]], dtype=np.float32)\n",
        "\n",
        "# LOAD MODEL\n",
        "print(f\"load model {MODEL_NAME}...\")\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = DepthAnything3.from_pretrained(f\"depth-anything/{MODEL_NAME}\").to(device)\n",
        "\n",
        "# BATCH\n",
        "print(f\"🏃 Running Batch\")\n",
        "\n",
        "for i in range(0, total_imgs, BATCH_SIZE):\n",
        "    batch_end = min(i + BATCH_SIZE, total_imgs)\n",
        "    batch_paths = all_image_paths[i : batch_end]\n",
        "    batch_int = np.tile(K[None, ...], (len(batch_paths), 1, 1))\n",
        "\n",
        "    print(f\"Processing batch {i} -> {batch_end}...\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        predictions = model.inference(\n",
        "            image=batch_paths,\n",
        "            extrinsics=None,\n",
        "            intrinsics=batch_int,\n",
        "            align_to_input_ext_scale=False,\n",
        "            export_dir=None,\n",
        "            export_format=\"mini_npz\"\n",
        "        )\n",
        "\n",
        "    depths = predictions.depth           # (B, H, W)\n",
        "    pred_poses = predictions.extrinsics  # (B, 4, 4)\n",
        "\n",
        "    for idx_in_batch, (depth_map, pose_matrix) in enumerate(zip(depths, pred_poses)):\n",
        "        global_idx = i + idx_in_batch\n",
        "\n",
        "        # DEPTH .NPY (Raw Float32)\n",
        "        filename_npy = f\"{global_idx:05d}_depth.npy\"\n",
        "        np.save(os.path.join(OUTPUT_DEPTH_DIR, filename_npy), depth_map)\n",
        "\n",
        "        # PREDICTED POSE .TXT (W2C)\n",
        "        filename_pose = f\"{global_idx:05d}_pose.txt\"\n",
        "        np.savetxt(os.path.join(OUTPUT_DEPTH_DIR, filename_pose), pose_matrix)\n",
        "\n",
        "        # Visualization\n",
        "        filename_png = f\"{global_idx:05d}.png\"\n",
        "        save_path = os.path.join(OUTPUT_DEPTH_DIR, filename_png)\n",
        "\n",
        "        d_min, d_max = depth_map.min(), depth_map.max()\n",
        "        if d_max - d_min > 0:\n",
        "            d_norm = (depth_map - d_min) / (d_max - d_min) * 255.0\n",
        "        else:\n",
        "            d_norm = depth_map * 0\n",
        "        d_color = cv2.applyColorMap(d_norm.astype(np.uint8), cv2.COLORMAP_INFERNO)\n",
        "        cv2.imwrite(save_path, d_color)\n",
        "\n",
        "    # Clean\n",
        "    del predictions, depths, pred_poses\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "print(f\"Kết quả lưu tại: {OUTPUT_DEPTH_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "87b2a6c38b844a0897f9785b776892f9",
            "2dffeaf4e9e6403b936ec8e4a9b8b1f2",
            "9bf6850a1f404c8fab2cc8d817f00265",
            "62268b039da24070af54a96386b73537",
            "2ba8e6c7df9243819eaf0b2e25d2f0b0",
            "fe01f8b0f15a448ebc5f9b72a8243b0f",
            "d4c57a39082a4c5c8bee1a29087cc9fa",
            "6c14828dba7f42319c2006ebcec0bb89",
            "d204b38752204c70957839264b9833cf",
            "ae0d6123eb1244869f08ef165fb96a9a",
            "90f495a2220147d8bd073753451d8605",
            "89577ab8f36344869172995ad5d00ea9",
            "cbe3f9a732b944099f9fe14c14ed28ac",
            "a1d504a167f343faba22d24fce75fc5b",
            "0baec7fb4f1f434d8fca26114deed4bb",
            "ff629129504e46e2b898ecbeed613f4b",
            "7770fd28ae0c416fa8136c1eeeeb7f30",
            "cec34eeaeb9c4d8ebab03341d571e6d0",
            "301ca8a38f944eb5a0f257a369f95d08",
            "6bc161a4ea964c5f807e47835d71e2be",
            "c81bdf8037fc492290895e7411714ee8",
            "ff94c89011484bd6941eac47ebddcf3c"
          ]
        },
        "id": "jUjZxT5PFDuA",
        "outputId": "fb408a84-3e13-4cbe-abf4-2d19b9c27997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/moviepy/config_defaults.py:47: SyntaxWarning: invalid escape sequence '\\P'\n",
            "  IMAGEMAGICK_BINARY = r\"C:\\Program Files\\ImageMagick-6.8.8-Q16\\magick.exe\"\n",
            "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:294: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  lines_video = [l for l in lines if ' Video: ' in l and re.search('\\d+x\\d+', l)]\n",
            "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:367: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  rotation_lines = [l for l in lines if 'rotate          :' in l and re.search('\\d+$', l)]\n",
            "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:370: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  match = re.search('\\d+$', rotation_line)\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with 'str' literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[93m[WARN ] Dependency `gsplat` is required for rendering 3DGS. Install via: pip install git+https://github.com/nerfstudio-project/gsplat.git@0b4dddf04cb687367602c01196913cde6a743d70\u001b[0m\n",
            "🚀 KHỞI ĐỘNG BLIND POSE MODE - MODEL: da3-large\n",
            "📦 Đang giải nén dataset...\n",
            "📸 Tổng số ảnh: 1201\n",
            "🧠 Đang load model da3-large...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87b2a6c38b844a0897f9785b776892f9"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[97m[INFO ] using MLP layer as FFN\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.64G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff94c89011484bd6941eac47ebddcf3c"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🏃 Bắt đầu chạy Batch (Model sẽ tự đoán Pose)...\n",
            "    👉 Processing batch 0 -> 18...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.162276029586792 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 3.89211368560791 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.02498006820678711 seconds\u001b[0m\n",
            "    👉 Processing batch 18 -> 36...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.09360337257385254 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.0625617504119873 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.024381399154663086 seconds\u001b[0m\n",
            "    👉 Processing batch 36 -> 54...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.08167052268981934 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.069908380508423 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.011047601699829102 seconds\u001b[0m\n",
            "    👉 Processing batch 54 -> 72...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.08216261863708496 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.056974172592163 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.007967710494995117 seconds\u001b[0m\n",
            "    👉 Processing batch 72 -> 90...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07776308059692383 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.0639116764068604 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.008064508438110352 seconds\u001b[0m\n",
            "    👉 Processing batch 90 -> 108...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.080596923828125 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.057546377182007 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.024922609329223633 seconds\u001b[0m\n",
            "    👉 Processing batch 108 -> 126...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.0848844051361084 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.0656938552856445 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.008046388626098633 seconds\u001b[0m\n",
            "    👉 Processing batch 126 -> 144...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.0799415111541748 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.0640599727630615 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.025063514709472656 seconds\u001b[0m\n",
            "    👉 Processing batch 144 -> 162...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07707905769348145 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.0680062770843506 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.008203744888305664 seconds\u001b[0m\n",
            "    👉 Processing batch 162 -> 180...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07552409172058105 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.060563564300537 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.025039196014404297 seconds\u001b[0m\n",
            "    👉 Processing batch 180 -> 198...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07810306549072266 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.0709760189056396 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.00812220573425293 seconds\u001b[0m\n",
            "    👉 Processing batch 198 -> 216...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07769441604614258 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.0701091289520264 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.02516460418701172 seconds\u001b[0m\n",
            "    👉 Processing batch 216 -> 234...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07741665840148926 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.0723419189453125 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.00821828842163086 seconds\u001b[0m\n",
            "    👉 Processing batch 234 -> 252...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07987046241760254 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.067770481109619 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.02506709098815918 seconds\u001b[0m\n",
            "    👉 Processing batch 252 -> 270...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07771134376525879 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.066976547241211 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.008090496063232422 seconds\u001b[0m\n",
            "    👉 Processing batch 270 -> 288...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07526946067810059 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.0759873390197754 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.02501058578491211 seconds\u001b[0m\n",
            "    👉 Processing batch 288 -> 306...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07124924659729004 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.07259464263916 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.008401632308959961 seconds\u001b[0m\n",
            "    👉 Processing batch 306 -> 324...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07675004005432129 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.0787720680236816 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.0249783992767334 seconds\u001b[0m\n",
            "    👉 Processing batch 324 -> 342...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07209491729736328 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.0771448612213135 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.007996082305908203 seconds\u001b[0m\n",
            "    👉 Processing batch 342 -> 360...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07408857345581055 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.078601121902466 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.025025129318237305 seconds\u001b[0m\n",
            "    👉 Processing batch 360 -> 378...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07852673530578613 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.078798294067383 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.008124828338623047 seconds\u001b[0m\n",
            "    👉 Processing batch 378 -> 396...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07660627365112305 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.081106185913086 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.025235414505004883 seconds\u001b[0m\n",
            "    👉 Processing batch 396 -> 414...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.08523201942443848 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.084989547729492 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.008264541625976562 seconds\u001b[0m\n",
            "    👉 Processing batch 414 -> 432...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.08008813858032227 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.086303234100342 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.02653980255126953 seconds\u001b[0m\n",
            "    👉 Processing batch 432 -> 450...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.08437609672546387 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.0839691162109375 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.008088350296020508 seconds\u001b[0m\n",
            "    👉 Processing batch 450 -> 468...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.0772700309753418 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.0804293155670166 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.025541067123413086 seconds\u001b[0m\n",
            "    👉 Processing batch 468 -> 486...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07467103004455566 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.0867440700531006 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.008304595947265625 seconds\u001b[0m\n",
            "    👉 Processing batch 486 -> 504...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07508587837219238 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.0929293632507324 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.025082111358642578 seconds\u001b[0m\n",
            "    👉 Processing batch 504 -> 522...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.08386611938476562 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.093485116958618 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.0081024169921875 seconds\u001b[0m\n",
            "    👉 Processing batch 522 -> 540...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07671523094177246 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.087336301803589 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.02495121955871582 seconds\u001b[0m\n",
            "    👉 Processing batch 540 -> 558...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07500696182250977 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.0912725925445557 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.008039236068725586 seconds\u001b[0m\n",
            "    👉 Processing batch 558 -> 576...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07749199867248535 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.0906434059143066 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.024941444396972656 seconds\u001b[0m\n",
            "    👉 Processing batch 576 -> 594...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07587194442749023 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.09218430519104 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.008193016052246094 seconds\u001b[0m\n",
            "    👉 Processing batch 594 -> 612...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.0747218132019043 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.09370756149292 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.02508831024169922 seconds\u001b[0m\n",
            "    👉 Processing batch 612 -> 630...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07522416114807129 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.0905895233154297 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.008100509643554688 seconds\u001b[0m\n",
            "    👉 Processing batch 630 -> 648...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07905125617980957 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.0947296619415283 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.025682449340820312 seconds\u001b[0m\n",
            "    👉 Processing batch 648 -> 666...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.08131933212280273 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.1001362800598145 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.008027791976928711 seconds\u001b[0m\n",
            "    👉 Processing batch 666 -> 684...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.06764459609985352 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.092005491256714 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.02476954460144043 seconds\u001b[0m\n",
            "    👉 Processing batch 684 -> 702...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.08142948150634766 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.098848342895508 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.008152246475219727 seconds\u001b[0m\n",
            "    👉 Processing batch 702 -> 720...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07692742347717285 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.1073215007781982 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.025379180908203125 seconds\u001b[0m\n",
            "    👉 Processing batch 720 -> 738...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.08016681671142578 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.0973498821258545 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.008052349090576172 seconds\u001b[0m\n",
            "    👉 Processing batch 738 -> 756...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07621192932128906 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.1096770763397217 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.026733875274658203 seconds\u001b[0m\n",
            "    👉 Processing batch 756 -> 774...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.08307576179504395 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.1112730503082275 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.008278369903564453 seconds\u001b[0m\n",
            "    👉 Processing batch 774 -> 792...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.0788578987121582 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.1077921390533447 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.02499079704284668 seconds\u001b[0m\n",
            "    👉 Processing batch 792 -> 810...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.08334898948669434 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.106492280960083 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.008173942565917969 seconds\u001b[0m\n",
            "    👉 Processing batch 810 -> 828...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.0764317512512207 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.1034302711486816 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.0250699520111084 seconds\u001b[0m\n",
            "    👉 Processing batch 828 -> 846...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07287406921386719 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.107900857925415 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.008129119873046875 seconds\u001b[0m\n",
            "    👉 Processing batch 846 -> 864...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07364201545715332 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.115495204925537 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.024924755096435547 seconds\u001b[0m\n",
            "    👉 Processing batch 864 -> 882...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07636833190917969 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.113867998123169 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.008097171783447266 seconds\u001b[0m\n",
            "    👉 Processing batch 882 -> 900...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.0747072696685791 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.107257127761841 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.02511143684387207 seconds\u001b[0m\n",
            "    👉 Processing batch 900 -> 918...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07856059074401855 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.1082351207733154 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.008245468139648438 seconds\u001b[0m\n",
            "    👉 Processing batch 918 -> 936...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07699704170227051 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.106015682220459 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.025097370147705078 seconds\u001b[0m\n",
            "    👉 Processing batch 936 -> 954...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07221841812133789 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.107909917831421 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.008036375045776367 seconds\u001b[0m\n",
            "    👉 Processing batch 954 -> 972...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07497310638427734 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.114074468612671 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.024915456771850586 seconds\u001b[0m\n",
            "    👉 Processing batch 972 -> 990...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.08092784881591797 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.109851360321045 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.010459184646606445 seconds\u001b[0m\n",
            "    👉 Processing batch 990 -> 1008...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.08329486846923828 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.1161251068115234 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.00816655158996582 seconds\u001b[0m\n",
            "    👉 Processing batch 1008 -> 1026...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07643866539001465 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.1086928844451904 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.01851177215576172 seconds\u001b[0m\n",
            "    👉 Processing batch 1026 -> 1044...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07644844055175781 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.1128408908843994 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.008197546005249023 seconds\u001b[0m\n",
            "    👉 Processing batch 1044 -> 1062...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.0800621509552002 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.1195781230926514 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.025188207626342773 seconds\u001b[0m\n",
            "    👉 Processing batch 1062 -> 1080...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.0790107250213623 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.1229355335235596 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.00808572769165039 seconds\u001b[0m\n",
            "    👉 Processing batch 1080 -> 1098...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07579803466796875 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.1165688037872314 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.025010347366333008 seconds\u001b[0m\n",
            "    👉 Processing batch 1098 -> 1116...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07836771011352539 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.118345260620117 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.008158206939697266 seconds\u001b[0m\n",
            "    👉 Processing batch 1116 -> 1134...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07944774627685547 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.1141602993011475 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.02506875991821289 seconds\u001b[0m\n",
            "    👉 Processing batch 1134 -> 1152...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.08345866203308105 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.1211507320404053 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.008167505264282227 seconds\u001b[0m\n",
            "    👉 Processing batch 1152 -> 1170...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.08025288581848145 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.123356342315674 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.025083303451538086 seconds\u001b[0m\n",
            "    👉 Processing batch 1170 -> 1188...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07201647758483887 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 2.1170504093170166 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.008176565170288086 seconds\u001b[0m\n",
            "    👉 Processing batch 1188 -> 1201...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.05508112907409668 seconds. Shape:  torch.Size([13, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Selecting reference view using strategy: saddle_balanced\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 1.4709153175354004 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.017950057983398438 seconds\u001b[0m\n",
            "--------------------------------------------------\n",
            "✅ HOÀN TẤT!\n",
            "📂 Kết quả lưu tại: /content/drive/MyDrive/3D_reconstruction/simcol_output_blind_pose/depth_pose_data\n",
            "ℹ️ File '_pose.txt' chứa ma trận Pose 4x4 do model tự tính toán.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DA3MONO-LARGE"
      ],
      "metadata": {
        "id": "E7GA_82U7ipA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import zipfile\n",
        "import gc\n",
        "from pathlib import Path\n",
        "from depth_anything_3.api import DepthAnything3\n",
        "\n",
        "ZIP_PATH = \"/content/drive/MyDrive/3D_reconstruction/datasets/FrameBuffer_RGB.zip\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/3D_reconstruction/simcol_output_mono\"\n",
        "OUTPUT_DEPTH_DIR = os.path.join(OUTPUT_DIR, \"depth_data\")\n",
        "\n",
        "MODEL_NAME = \"da3mono-large\"\n",
        "BATCH_SIZE = 18\n",
        "\n",
        "# INTRINSIC\n",
        "FX, FY = 227.60416, 237.5\n",
        "CX, CY = 227.60416, 237.5\n",
        "\n",
        "print(f\"MODEL: {MODEL_NAME}\")\n",
        "os.makedirs(OUTPUT_DEPTH_DIR, exist_ok=True)\n",
        "\n",
        "EXTRACT_PATH = \"/content/dataset_simcol_rgb\"\n",
        "if not os.path.exists(EXTRACT_PATH):\n",
        "    print(f\"Extract dataset\")\n",
        "    with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
        "        zip_ref.extractall(EXTRACT_PATH)\n",
        "\n",
        "# List ảnh\n",
        "image_extensions = {'.png', '.jpg'}\n",
        "all_image_paths = sorted([\n",
        "    str(p) for p in Path(EXTRACT_PATH).rglob(\"*\")\n",
        "    if p.suffix.lower() in image_extensions\n",
        "])\n",
        "total_imgs = len(all_image_paths)\n",
        "print(f\"Tổng số ảnh: {total_imgs}\")\n",
        "\n",
        "# Intrinsic\n",
        "K = np.array([[FX, 0, CX], [0, FY, CY], [0, 0, 1]], dtype=np.float32)\n",
        "\n",
        "# LOAD MODEL\n",
        "print(f\"🧠 Đang load model {MODEL_NAME}...\")\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = DepthAnything3.from_pretrained(f\"depth-anything/{MODEL_NAME}\").to(device)\n",
        "\n",
        "# RUNNING\n",
        "print(f\"Running Batch\")\n",
        "\n",
        "for i in range(0, total_imgs, BATCH_SIZE):\n",
        "    batch_end = min(i + BATCH_SIZE, total_imgs)\n",
        "    batch_paths = all_image_paths[i : batch_end]\n",
        "    batch_int = np.tile(K[None, ...], (len(batch_paths), 1, 1))\n",
        "\n",
        "    print(f\"Processing batch {i} -> {batch_end}...\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        predictions = model.inference(\n",
        "            image=batch_paths,\n",
        "            extrinsics=None,\n",
        "            intrinsics=batch_int,\n",
        "            align_to_input_ext_scale=False,\n",
        "            export_dir=None,\n",
        "            export_format=\"mini_npz\"\n",
        "        )\n",
        "\n",
        "    depths = predictions.depth  # (B, H, W)\n",
        "\n",
        "    for idx_in_batch, depth_map in enumerate(depths):\n",
        "        global_idx = i + idx_in_batch\n",
        "        filename = f\"{global_idx:05d}\"\n",
        "\n",
        "        # DEPTH .NPY\n",
        "        np.save(os.path.join(OUTPUT_DEPTH_DIR, f\"{filename}.npy\"), depth_map)\n",
        "\n",
        "        # Visualization\n",
        "        save_path_img = os.path.join(OUTPUT_DEPTH_DIR, f\"{filename}.png\")\n",
        "\n",
        "        # Normalize\n",
        "        d_min, d_max = depth_map.min(), depth_map.max()\n",
        "        if d_max - d_min > 0:\n",
        "            d_norm = (depth_map - d_min) / (d_max - d_min) * 255.0\n",
        "        else:\n",
        "            d_norm = depth_map * 0\n",
        "\n",
        "        d_color = cv2.applyColorMap(d_norm.astype(np.uint8), cv2.COLORMAP_INFERNO)\n",
        "        cv2.imwrite(save_path_img, d_color)\n",
        "\n",
        "    # Clean\n",
        "    del predictions, depths\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "print(f\"📂 Output tại: {OUTPUT_DEPTH_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f754258eb36542a49bd2677d69771007",
            "f1b8c3ef8c5546a8ace4bb7a938a2f6d",
            "0004c453b65c4bbaa2668622a88122cd",
            "48a5a05b71ee4e7c98059566f19192fe",
            "87795ea95574475eaade7aedf9684bd6",
            "d3716c8997fc4ed7bc8c2a67203130f6",
            "aaa80626a0294d2ea0afaa5473e2f049",
            "b97b3e247b644a398ba307b12998377f",
            "8697d47724734b93b97a84cf3cb797f2",
            "e8131d99532d491b82b3cdd8ffb36d26",
            "7f8e680449104c27b3789d0cf85be200",
            "b4655b04f5fd42fa8b7a49a42859b601",
            "60f6da7b317148ecbefc52e8ff4e5198",
            "ee53bb7a593243f5b27e0f33cbad1152",
            "2b0148f609af402391604b6bbf273649",
            "2408ec34b1534081b1fb1c26afb28ff6",
            "5926d826b69e44258e5fe2dab4b8411c",
            "6ba0e5f3e06f4e0b8bde2c3fbfbcfc75",
            "6fe65d9b03cd409490f057c5a9078da2",
            "810ea732722c4099aea40caa96c2f564",
            "9af13f1bfbb94cd5b32a5a983740ac9a",
            "0775b43336544f6295381fa2ad158312"
          ]
        },
        "id": "Ru8pm9wzFqgx",
        "outputId": "fdf71e0a-a768-4b45-bcda-f7b74c58b222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 KHỞI ĐỘNG MONO MODE - MODEL: da3mono-large\n",
            "📸 Tổng số ảnh: 1201\n",
            "🧠 Đang load model da3mono-large...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/845 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f754258eb36542a49bd2677d69771007"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[97m[INFO ] using MLP layer as FFN\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0775b43336544f6295381fa2ad158312"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🏃 Bắt đầu chạy Batch (Relative Depth)...\n",
            "    👉 Processing batch 0 -> 18...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07575631141662598 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 1.050619125366211 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009758949279785156 seconds\u001b[0m\n",
            "    👉 Processing batch 18 -> 36...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.0797417163848877 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.995380163192749 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009916543960571289 seconds\u001b[0m\n",
            "    👉 Processing batch 36 -> 54...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07736968994140625 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9905836582183838 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009920120239257812 seconds\u001b[0m\n",
            "    👉 Processing batch 54 -> 72...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07323169708251953 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9918866157531738 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009744882583618164 seconds\u001b[0m\n",
            "    👉 Processing batch 72 -> 90...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07362747192382812 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9944984912872314 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009754180908203125 seconds\u001b[0m\n",
            "    👉 Processing batch 90 -> 108...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07124543190002441 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9916372299194336 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009887456893920898 seconds\u001b[0m\n",
            "    👉 Processing batch 108 -> 126...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.0819692611694336 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9962539672851562 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009771108627319336 seconds\u001b[0m\n",
            "    👉 Processing batch 126 -> 144...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.08085155487060547 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9933834075927734 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009820699691772461 seconds\u001b[0m\n",
            "    👉 Processing batch 144 -> 162...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07276296615600586 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9969005584716797 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009802818298339844 seconds\u001b[0m\n",
            "    👉 Processing batch 162 -> 180...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07220220565795898 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9910273551940918 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009841203689575195 seconds\u001b[0m\n",
            "    👉 Processing batch 180 -> 198...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.06984639167785645 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9880518913269043 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.010214090347290039 seconds\u001b[0m\n",
            "    👉 Processing batch 198 -> 216...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.0769340991973877 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9904434680938721 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009644508361816406 seconds\u001b[0m\n",
            "    👉 Processing batch 216 -> 234...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.0691380500793457 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9890847206115723 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009646415710449219 seconds\u001b[0m\n",
            "    👉 Processing batch 234 -> 252...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.06812453269958496 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9951951503753662 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009614229202270508 seconds\u001b[0m\n",
            "    👉 Processing batch 252 -> 270...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07775735855102539 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9947042465209961 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009783267974853516 seconds\u001b[0m\n",
            "    👉 Processing batch 270 -> 288...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07435297966003418 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9949381351470947 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009801387786865234 seconds\u001b[0m\n",
            "    👉 Processing batch 288 -> 306...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07085585594177246 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9969773292541504 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.00962686538696289 seconds\u001b[0m\n",
            "    👉 Processing batch 306 -> 324...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07039332389831543 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9944634437561035 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009368658065795898 seconds\u001b[0m\n",
            "    👉 Processing batch 324 -> 342...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07936549186706543 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9970581531524658 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009832382202148438 seconds\u001b[0m\n",
            "    👉 Processing batch 342 -> 360...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07049918174743652 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9949557781219482 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009872674942016602 seconds\u001b[0m\n",
            "    👉 Processing batch 360 -> 378...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.09101343154907227 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9913139343261719 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.01014399528503418 seconds\u001b[0m\n",
            "    👉 Processing batch 378 -> 396...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07343363761901855 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9934816360473633 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009380578994750977 seconds\u001b[0m\n",
            "    👉 Processing batch 396 -> 414...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07547426223754883 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9915425777435303 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009824275970458984 seconds\u001b[0m\n",
            "    👉 Processing batch 414 -> 432...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.06676983833312988 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.989830732345581 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009613513946533203 seconds\u001b[0m\n",
            "    👉 Processing batch 432 -> 450...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07514023780822754 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9940643310546875 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009730815887451172 seconds\u001b[0m\n",
            "    👉 Processing batch 450 -> 468...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07276034355163574 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9971160888671875 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.00986170768737793 seconds\u001b[0m\n",
            "    👉 Processing batch 468 -> 486...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07582592964172363 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9979567527770996 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009711742401123047 seconds\u001b[0m\n",
            "    👉 Processing batch 486 -> 504...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.0777280330657959 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9953057765960693 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009579896926879883 seconds\u001b[0m\n",
            "    👉 Processing batch 504 -> 522...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07915639877319336 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9969358444213867 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009639501571655273 seconds\u001b[0m\n",
            "    👉 Processing batch 522 -> 540...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07213449478149414 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9951415061950684 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009464740753173828 seconds\u001b[0m\n",
            "    👉 Processing batch 540 -> 558...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.06778788566589355 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9990959167480469 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009792804718017578 seconds\u001b[0m\n",
            "    👉 Processing batch 558 -> 576...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07178425788879395 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9938056468963623 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009791851043701172 seconds\u001b[0m\n",
            "    👉 Processing batch 576 -> 594...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.06782770156860352 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9963300228118896 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009830951690673828 seconds\u001b[0m\n",
            "    👉 Processing batch 594 -> 612...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.06929326057434082 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9981491565704346 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009720563888549805 seconds\u001b[0m\n",
            "    👉 Processing batch 612 -> 630...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07557082176208496 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9999027252197266 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009467840194702148 seconds\u001b[0m\n",
            "    👉 Processing batch 630 -> 648...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07242059707641602 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 1.003011703491211 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009870767593383789 seconds\u001b[0m\n",
            "    👉 Processing batch 648 -> 666...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07192778587341309 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9928791522979736 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.00941610336303711 seconds\u001b[0m\n",
            "    👉 Processing batch 666 -> 684...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07178521156311035 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9975035190582275 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009521007537841797 seconds\u001b[0m\n",
            "    👉 Processing batch 684 -> 702...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.06837344169616699 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9997603893280029 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009839534759521484 seconds\u001b[0m\n",
            "    👉 Processing batch 702 -> 720...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.06773853302001953 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9961762428283691 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009733200073242188 seconds\u001b[0m\n",
            "    👉 Processing batch 720 -> 738...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.06595182418823242 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 1.0012786388397217 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009624481201171875 seconds\u001b[0m\n",
            "    👉 Processing batch 738 -> 756...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07312536239624023 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9943172931671143 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009595632553100586 seconds\u001b[0m\n",
            "    👉 Processing batch 756 -> 774...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07189702987670898 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9968297481536865 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009820699691772461 seconds\u001b[0m\n",
            "    👉 Processing batch 774 -> 792...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.06984686851501465 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.996058464050293 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009578466415405273 seconds\u001b[0m\n",
            "    👉 Processing batch 792 -> 810...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.0690927505493164 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9991405010223389 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.010016918182373047 seconds\u001b[0m\n",
            "    👉 Processing batch 810 -> 828...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.06937932968139648 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9956796169281006 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009420394897460938 seconds\u001b[0m\n",
            "    👉 Processing batch 828 -> 846...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07092952728271484 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9953305721282959 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.00980234146118164 seconds\u001b[0m\n",
            "    👉 Processing batch 846 -> 864...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07338929176330566 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 1.0011937618255615 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009790420532226562 seconds\u001b[0m\n",
            "    👉 Processing batch 864 -> 882...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.0804290771484375 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9998195171356201 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.00972747802734375 seconds\u001b[0m\n",
            "    👉 Processing batch 882 -> 900...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.0654904842376709 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 1.0008363723754883 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009797334671020508 seconds\u001b[0m\n",
            "    👉 Processing batch 900 -> 918...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.06985759735107422 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9989838600158691 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009574413299560547 seconds\u001b[0m\n",
            "    👉 Processing batch 918 -> 936...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.06428766250610352 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9973528385162354 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009516000747680664 seconds\u001b[0m\n",
            "    👉 Processing batch 936 -> 954...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07296061515808105 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 1.0001344680786133 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009508371353149414 seconds\u001b[0m\n",
            "    👉 Processing batch 954 -> 972...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.06977033615112305 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9999516010284424 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009647130966186523 seconds\u001b[0m\n",
            "    👉 Processing batch 972 -> 990...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.08182144165039062 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 1.0020711421966553 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009702205657958984 seconds\u001b[0m\n",
            "    👉 Processing batch 990 -> 1008...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07720780372619629 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9975190162658691 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009556055068969727 seconds\u001b[0m\n",
            "    👉 Processing batch 1008 -> 1026...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.06866240501403809 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 1.0035510063171387 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.00959920883178711 seconds\u001b[0m\n",
            "    👉 Processing batch 1026 -> 1044...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07697725296020508 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9969527721405029 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009726285934448242 seconds\u001b[0m\n",
            "    👉 Processing batch 1044 -> 1062...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.06928777694702148 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 1.0027341842651367 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.00982809066772461 seconds\u001b[0m\n",
            "    👉 Processing batch 1062 -> 1080...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07275104522705078 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 1.0037147998809814 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009646415710449219 seconds\u001b[0m\n",
            "    👉 Processing batch 1080 -> 1098...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.0724327564239502 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 1.0000050067901611 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009524106979370117 seconds\u001b[0m\n",
            "    👉 Processing batch 1098 -> 1116...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.0728604793548584 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 1.0064666271209717 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009591341018676758 seconds\u001b[0m\n",
            "    👉 Processing batch 1116 -> 1134...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.06751108169555664 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 1.0025293827056885 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009721517562866211 seconds\u001b[0m\n",
            "    👉 Processing batch 1134 -> 1152...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07883977890014648 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 1.0030488967895508 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009669780731201172 seconds\u001b[0m\n",
            "    👉 Processing batch 1152 -> 1170...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.07306098937988281 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9976508617401123 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009767532348632812 seconds\u001b[0m\n",
            "    👉 Processing batch 1170 -> 1188...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.0742485523223877 seconds. Shape:  torch.Size([18, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.9981734752655029 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.009608745574951172 seconds\u001b[0m\n",
            "    👉 Processing batch 1188 -> 1201...\n",
            "\u001b[97m[INFO ] Processed Images Done taking 0.052084922790527344 seconds. Shape:  torch.Size([13, 3, 504, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.7158782482147217 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.007131814956665039 seconds\u001b[0m\n",
            "--------------------------------------------------\n",
            "✅ HOÀN TẤT!\n",
            "📂 Output tại: /content/drive/MyDrive/3D_reconstruction/simcol_output_mono/depth_data\n",
            "ℹ️ Model này (Mono) cho độ chi tiết bề mặt tốt nhất, nhưng tỉ lệ (scale) chưa chuẩn mét.\n"
          ]
        }
      ]
    }
  ]
}